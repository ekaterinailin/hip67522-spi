{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import ultranest\n",
    "\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20489794627752925\n"
     ]
    }
   ],
   "source": [
    "# read phases from file\n",
    "tess_phases = np.loadtxt(\"../data/tess_phases.txt\")\n",
    "cheops_phases = np.loadtxt(\"../data/cheops_phases.txt\")\n",
    "\n",
    "# weigh by observing cadence\n",
    "weights = np.concatenate([np.ones_like(cheops_phases) * 10. / 60. / 60. / 24., np.ones_like(tess_phases) * 2. / 60. / 24.] )\n",
    "obs_phases = np.concatenate([cheops_phases, tess_phases])\n",
    "\n",
    "# flare phases\n",
    "phases = np.array([0.61248919, 0.81165721, 0.01788908, 0.0296636,  0.05760315, 0.04067287,\n",
    "0.73005547, 0.94878914, 0.11323833, 0.20031473, 0.15087211, 0.04514247,\n",
    "0.02527212, 0.05657772, 0.06247738, ]) \n",
    "\n",
    "# phases = np.random.rand(15)\n",
    "\n",
    "# shift by 0.5\n",
    "obs_phases = (obs_phases + 0.5) % 1\n",
    "phases = (phases + 0.5) % 1\n",
    "\n",
    "# define binning\n",
    "nbins = 75\n",
    "bins = np.linspace(0, 1, nbins)\n",
    "binmids= (bins[1:] + bins[:-1]) / 2\n",
    "\n",
    "# bin the phases\n",
    "arr = np.digitize(obs_phases, bins)\n",
    "\n",
    "# sum the observing times in each bin to binned weights\n",
    "# unit of entries in binned is [days]\n",
    "binned = np.array([np.sum(weights[arr==i]) for i in range(1, len(bins))]) \n",
    "\n",
    "print(len(phases) / np.sum(binned))\n",
    "\n",
    "\n",
    "# define the two models we want to compare\n",
    "def modulated_model(binmids, lambda0, lambda1, phase0, dphase, weight=binned):\n",
    "    mask = (binmids > phase0) & (binmids < (phase0 + dphase)%1)\n",
    "    result = np.zeros_like(binmids)\n",
    "\n",
    "    # multiply by weight because that modifies the measured rate\n",
    "    result[~mask] = lambda0 * weight[~mask]\n",
    "    result[mask] = lambda1 * weight[mask]\n",
    "\n",
    "    return result #number of observed flares per bin\n",
    "\n",
    "def unmodulated_model(lambda0, weight=binned):\n",
    "    return lambda0 * weight #number of observed flares per bin\n",
    "\n",
    "# observed:\n",
    "hist, bins = np.histogram(phases, bins=bins)\n",
    "\n",
    "# define the factorials for the numbers in hist for the likelihood computation\n",
    "factorials = np.array([factorial(h) for h in hist])\n",
    "\n",
    "# Poisson log-likelihood function\n",
    "def likelihood_poisson(rate, hist, factorials):\n",
    "    logs = -rate - np.log(factorials) + np.log(rate) * hist\n",
    "    return np.sum(logs)\n",
    "\n",
    "# log-likelihood for the modulated model\n",
    "def likelihood_mod(params):\n",
    "\n",
    "    rate = modulated_model(binmids, *params, weight=binned)\n",
    "\n",
    "    return likelihood_poisson(rate, hist, factorials)\n",
    "\n",
    "p1 = [\"lambda0\", \"lambda1\", \"phase0\", \"dphase\"]\n",
    "\n",
    "def prior_transform_mod(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "\n",
    "    params = cube.copy()\n",
    "    # lambda0 from 0 to 4 flat\n",
    "    params[0] = cube[0] * 4 \n",
    "    # lambda1 from 0 to 4 flat\n",
    "    params[1] = cube[1] * 4\n",
    "    # phase zero from 0 to 1\n",
    "    params[2] = cube[2]\n",
    "    # dphase from 0 to 0.5\n",
    "    params[3] = cube[3] * 0.5\n",
    "    return params\n",
    "\n",
    "\n",
    "p0 = [\"lambda0\"]\n",
    "\n",
    "def prior_transform_unmod(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "\n",
    "    params = cube.copy()\n",
    "    # lambda0 from 0 to 4 flat\n",
    "    params[0] = cube[0] * 4\n",
    "  \n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "# define log-likelihood, prior, and probability\n",
    "def likelihood_unmod(params):\n",
    "    lambda0 = params[0]\n",
    "    rate = unmodulated_model(lambda0, weight=binned)\n",
    "    return likelihood_poisson(rate, hist, factorials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1 = [\"lambda0\", \"lambda1\", \"phase0\", \"dphase\"]\n",
    "\n",
    "sampler1 = ultranest.ReactiveNestedSampler(p1, likelihood_mod, prior_transform_mod)\n",
    "\n",
    "sampler0 = ultranest.ReactiveNestedSampler(p0, likelihood_unmod, prior_transform_unmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Sampling 7000 live points from prior ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbd4db082ce4017beff9a12d4f6ddd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), GridspecLayout(children=(HTML(value=\"<div style='background-color:#6E6BF4;'>&nb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Explored until L=-3e+01   [-28.9527..-28.9527]*| it/evals=110040/653768 eff=17.0138% N=7000 \n",
      "[ultranest] Likelihood function evaluations: 653781\n",
      "[ultranest]   logZ = -40.04 +- 0.02276\n",
      "[ultranest] Effective samples strategy satisfied (ESS = 59643.1, need >400)\n",
      "[ultranest] Posterior uncertainty strategy is satisfied (KL: 0.46+-0.02 nat, need <0.50 nat)\n",
      "[ultranest] Evidency uncertainty strategy is satisfied (dlogz=0.02, need <0.5)\n",
      "[ultranest]   logZ error budget: single: 0.03 bs:0.02 tail:0.01 total:0.02 required:<0.50\n",
      "[ultranest] done iterating.\n",
      "\n",
      "logZ = -40.037 +- 0.048\n",
      "  single instance: logZ = -40.037 +- 0.032\n",
      "  bootstrapped   : logZ = -40.038 +- 0.047\n",
      "  tail           : logZ = +- 0.010\n",
      "insert order U test : converged: True correlation: inf iterations\n",
      "\n",
      "    lambda0             : 0.000 │▁▁▂▄▆▇▇▇▇▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ │0.543     0.118 +- 0.057\n",
      "    lambda1             : 0.00  │▁▁▂▅▇▇▇▆▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁│4.00      0.89 +- 0.58\n",
      "    phase0              : 0.00  │▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▂▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁│1.00      0.50 +- 0.11\n",
      "    dphase              : 0.00  │▁▁▁▄▇▄▂▂▂▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁│0.50      0.18 +- 0.11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = sampler1.run(min_num_live_points=7000)\n",
    "sampler1.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Sampling 400 live points from prior ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcec0e70a3d242489125606150f50ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), GridspecLayout(children=(HTML(value=\"<div style='background-color:#6E6BF4;'>&nb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Explored until L=-4e+01   [-38.2277..-38.2277]*| it/evals=2640/3108 eff=97.4889% N=400  \n",
      "[ultranest] Likelihood function evaluations: 3148\n",
      "[ultranest]   logZ = -41.61 +- 0.0576\n",
      "[ultranest] Effective samples strategy satisfied (ESS = 1271.9, need >400)\n",
      "[ultranest] Posterior uncertainty strategy is satisfied (KL: 0.46+-0.07 nat, need <0.50 nat)\n",
      "[ultranest] Evidency uncertainty strategy is satisfied (dlogz=0.07, need <0.5)\n",
      "[ultranest]   logZ error budget: single: 0.09 bs:0.06 tail:0.04 total:0.07 required:<0.50\n",
      "[ultranest] done iterating.\n",
      "\n",
      "logZ = -41.625 +- 0.127\n",
      "  single instance: logZ = -41.625 +- 0.085\n",
      "  bootstrapped   : logZ = -41.608 +- 0.122\n",
      "  tail           : logZ = +- 0.036\n",
      "insert order U test : converged: True correlation: inf iterations\n",
      "\n",
      "    lambda0             : 0.047 │ ▁ ▁▁▁▂▃▃▄▅▆▆▇▇▇▇▇▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁ │0.467     0.219 +- 0.055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result0 = sampler0.run(min_num_live_points=400)\n",
    "sampler0.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4.90\n",
      "The modulated model is 4.90 times more probable than the no-signal model\n",
      "assuming the models are equally probable a priori.\n"
     ]
    }
   ],
   "source": [
    "K = np.exp(result1['logz'] - result0['logz'])\n",
    "print(\"K = %.2f\" % K)\n",
    "print(\"The modulated model is %.2f times more probable than the no-signal model\" % K)\n",
    "print(\"assuming the models are equally probable a priori.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 3.34 3.8\n",
    "\n",
    "150 5.74 6.5\n",
    "\n",
    "100 5.26 5.6\n",
    "\n",
    "75  4.9 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_phases = np.loadtxt(\"../data/tess_phases.txt\")\n",
    "cheops_phases = np.loadtxt(\"../data/cheops_phases.txt\")\n",
    "flares = pd.read_csv(\"../results/flare_phases_and_energies.csv\")\n",
    "flares = flares.sort_values(\"ed_rec\", ascending=True).iloc[1:] # exclude the smallest flare\n",
    "\n",
    "# weigh by observing cadence\n",
    "weights = np.concatenate([np.ones_like(cheops_phases) * 10. / 60. / 60. / 24., np.ones_like(tess_phases) * 2. / 60. / 24.] )\n",
    "obs_phases = np.concatenate([cheops_phases, tess_phases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.949305555555554, 55.257870370370355, 73.20717592592591)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = obs_phases < 0.2\n",
    "nsmall, nbig = weights[mask].sum(), weights[~mask].sum()\n",
    "nsmall, nbig, nsmall + nbig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
